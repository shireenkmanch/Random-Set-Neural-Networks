{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "from data.id_dataloader import load_cifar10, load_intel_image, load_mnist, load_cifar100\n",
    "from data.ood_dataloader import load_ood_data, load_ood_svhn, load_ood_intel_image, load_ood_fashion_mnist, load_ood_kmnist\n",
    "from data.classes import cifar10_classes, mnist_classes, intel_image_classes, cifar100_classes\n",
    "from data.adversarial_data import add_random_noise, rotate_images\n",
    "\n",
    "from models.models import resnet50, wideresnet2810, vgg16, inceptionv3, efficientnetb2\n",
    "from models.pretrained_models import pretrained_resnet50, pretrained_vgg16\n",
    "\n",
    "from rsnn_functions.rsnn_loss import BinaryCrossEntropy\n",
    "from rsnn_functions.belief_mass_betp import belief_to_mass, final_betp\n",
    "\n",
    "from utils.eval_utils import load_model, load_all_predictions\n",
    "from utils.train_utils import train_val_split\n",
    "\n",
    "from metrics.uncertainty_metrics import entropy, compute_vertices, credal_set_width, specificity_metric\n",
    "from metrics.ood_metrics import evaluate_metrics\n",
    "from metrics.calibration_metrics import expected_calibration_error, calculate_and_print_ece\n",
    "from metrics.classification_metrics import compute_confidence_scores, compute_correct_incorrect_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    num_gpus = len(gpus)\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    # Set GPUs to use. For example, limit TensorFlow to use 3 GPUs\n",
    "    tf.config.experimental.set_visible_devices(gpus[:3], 'GPU')\n",
    "    \n",
    "# Create a MirroredStrategy for multi-GPU use\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configurations\n",
    "selected_dataset = \"cifar10\"  # Choose the dataset\n",
    "selected_model = \"resnet50\"   # Choose the model\n",
    "ood_dataset_1 = \"ood_svhn\" # Choose OoD datasets\n",
    "ood_dataset_2 = \"ood_intel_image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = {\"cifar10\": 10, \"mnist\": 10, \"intel_image\": 6, \"cifar100\": 100, \"svhn\": 10, \"fmnist\": 10, \"kmnist\":10}\n",
    "\n",
    "dataset_loader = {\n",
    " \"cifar10\": load_cifar10, \n",
    " \"mnist\": load_mnist, \n",
    " \"intel_image\": load_intel_image, \n",
    " \"cifar100\": load_cifar100, \n",
    " \"ood_svhn\": load_ood_svhn, \n",
    " \"ood_intel_image\": load_ood_intel_image,\n",
    " \"ood_fashion_mnist\": load_ood_fashion_mnist, \n",
    " \"ood_kmnist\":load_ood_kmnist\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"resnet50\": resnet50, \n",
    "    \"wideresnet_28_10\": wideresnet2810, \n",
    "    \"vgg16\": vgg16,\n",
    "    \"inception_v3\": inceptionv3,\n",
    "    \"efficientnet_b2\": efficientnetb2\n",
    "}\n",
    "\n",
    "pretrained_models = {\n",
    "    \"pretrained_resnet50\": pretrained_resnet50, \n",
    "    \"pretrained_vgg16\": pretrained_vgg16,\n",
    "}\n",
    "\n",
    "class_list_functions = {\n",
    "    \"cifar10\": cifar10_classes,\n",
    "     \"mnist\": mnist_classes, \n",
    "    \"intel_image\": intel_image_classes, \n",
    "    \"cifar100\": cifar100_classes, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class list\n",
    "classes = class_list_functions[selected_dataset]()\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "# Load dataset based on selected_dataset\n",
    "x_train, y_train, x_test_org, x_test, y_test = dataset_loader[selected_dataset]()\n",
    "\n",
    "# Infer input_shape based on selected_dataset\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# One-hot encoding of test labels\n",
    "y_test_one_hot = tf.one_hot(y_test, num_classes[selected_dataset])\n",
    "\n",
    "# Train-validation split\n",
    "x_train, y_train, y_train_one_hot, x_val, y_val, y_val_one_hot = train_val_split(x_train, y_train, num_classes[selected_dataset], val_samples=-10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Load saved CNN model\n",
    "\"\"\"\n",
    "# Multi-GPU run\n",
    "with strategy.scope():      \n",
    "    # Create the model based on selected_model\n",
    "    if selected_model in pretrained_models:\n",
    "        model = pretrained_models[selected_model](input_shape=input_shape, num_classes=num_classes[selected_dataset], final_activation='softmax')\n",
    "    else:\n",
    "        model = models[selected_model](input_shape=input_shape, num_classes=num_classes[selected_dataset], final_activation='softmax')\n",
    "    \n",
    "    # Compile the model \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=\"adam\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model = load_model(selected_model, selected_dataset, model_type = \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Load saved RS-NN model\n",
    "\"\"\"\n",
    "new_classes = np.load('new_classes.npy', allow_pickle=True)\n",
    "\n",
    "# Multi-GPU run\n",
    "with strategy.scope():      \n",
    "    # Create the model based on selected_model\n",
    "    if selected_model in pretrained_models:\n",
    "        new_model = pretrained_models[selected_model](input_shape=input_shape,  num_classes=len(new_classes), final_activation='sigmoid')\n",
    "    else:\n",
    "        new_model = models[selected_model](input_shape=input_shape, num_classes=len(new_classes), final_activation='sigmoid')\n",
    "\n",
    "    # Compile the model \n",
    "    new_model.compile(loss=BinaryCrossEntropy,\n",
    "                optimizer=\"adam\",\n",
    "                metrics=['binary_accuracy'])\n",
    "\n",
    "new_model = load_model(selected_model, selected_dataset, model_type = \"RSNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy of RS-NN and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and calculate accuracy of RS-NN\n",
    "new_classes_with_full = list(new_classes) + [set(classes)]\n",
    "new_classes_with_full, len(new_classes_with_full)\n",
    "\n",
    "test_preds = new_model.predict(x_test, verbose=1)\n",
    "test_preds_mass = belief_to_mass(test_preds, list(new_classes))\n",
    "final_bet_p = final_betp(test_preds_mass, classes, new_classes_with_full)\n",
    "\n",
    "final_bet_p_indices = np.argmax(final_bet_p, axis = -1)\n",
    "accuracy = (np.sum(final_bet_p_indices == y_test)/len(y_test))*100\n",
    "print(f\"Test Accuracy of RS-NN using pignistic probability: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and calculate accuracy of CNN\n",
    "y_pred = model.predict(x_test)\n",
    "score = model.evaluate(x_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy of standard CNN for test images: {score[1]*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample predictions by RS-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 1\n",
    "\n",
    "for im_index in np.random.randint(0, len(test_preds), number_of_samples):\n",
    "  plt.figure(figsize=(4,4), dpi=40)\n",
    "  im = x_test_org[im_index]\n",
    "  plt.imshow(im, cmap=\"gray\")\n",
    "  plt.title(str(classes[y_test[im_index]]))\n",
    "  plt.show()\n",
    "  top_labels = np.argsort(test_preds[im_index])[::-1][:5]\n",
    "  for t in top_labels:\n",
    "    print(f\"{new_classes[t]}\\t\\t\\t{test_preds[im_index][t]}\")\n",
    "  \n",
    "  print(\"\\n-------------Mass Values----------------------------\")\n",
    "  top_labels_mass = np.argsort(test_preds_mass[im_index])[::-1][:5]\n",
    "  for t in top_labels_mass:\n",
    "    print(f\"{new_classes_with_full[t]}\\t\\t\\t{test_preds_mass[im_index][t]}\")\n",
    "  \n",
    "  print(\"\\n-------------Pignistic Probabilities----------------------------\")\n",
    "  top_labels_pignistic = np.argsort(final_bet_p[im_index])[::-1][:5]\n",
    "  for t in top_labels_pignistic:\n",
    "    print(f\"{classes[t]}\\t\\t\\t{final_bet_p[im_index][t]}\")\n",
    "      \n",
    "  print(\"\\n-------------Entropy----------------------------\")\n",
    "  print(f\"\\t{entropy(final_bet_p)[im_index]}\")\n",
    "\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-distribution(OoD) detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OoD datasets corresponding to selected dataset\n",
    "test_preds = {}\n",
    "final_bet_ps = {}\n",
    "y_preds = {}\n",
    "test_preds_masses = {}\n",
    "ood_datasets = load_ood_data(selected_dataset, dataset_loader)\n",
    "ood_dataset_names = [ood_dataset_1, ood_dataset_2]\n",
    "\n",
    "for ood_dataset_name in ood_dataset_names:\n",
    "    x_test_ood = ood_datasets[ood_dataset_name]['x_test']\n",
    "    test_preds[ood_dataset_name] = new_model.predict(x_test_ood, verbose=1)\n",
    "    test_preds_masses[ood_dataset_name] = belief_to_mass(test_preds[ood_dataset_name], list(new_classes))\n",
    "    final_bet_ps[ood_dataset_name] = final_betp(test_preds_masses[ood_dataset_name], classes, new_classes_with_full)\n",
    "    y_preds[ood_dataset_name] = model.predict(x_test_ood)\n",
    "\n",
    "# RS-NN predictions on OoD datasets   \n",
    "final_bet_p_1 = final_bet_ps[ood_dataset_1]\n",
    "final_bet_p_2 = final_bet_ps[ood_dataset_2]\n",
    "\n",
    "# CNN predictions on OoD datasets   \n",
    "y_pred_1 = y_preds[ood_dataset_1]\n",
    "y_pred_2 = y_preds[ood_dataset_2]\n",
    "\n",
    "# Baseline (LB-BNN, ENN) predictions on OoD datasets   \n",
    "lbbnn_preds_id, lbbnn_preds_1, lbbnn_preds_2, enn_preds_id, enn_preds_1, enn_preds_2 = load_all_predictions(selected_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {\n",
    "    \"RS-NN\": {selected_dataset: final_bet_p, \"ood_dataset_1\": final_bet_p_1, \"ood_dataset_2\": final_bet_p_2},\n",
    "    \"LB-BNN\": {selected_dataset: lbbnn_preds_id, \"ood_dataset_1\": lbbnn_preds_1, \"ood_dataset_2\": lbbnn_preds_2},\n",
    "    \"ENN\": {selected_dataset: enn_preds_id, \"ood_dataset_1\": enn_preds_1, \"ood_dataset_2\": enn_preds_2},\n",
    "    \"CNN\": {selected_dataset: y_pred, \"ood_dataset_1\": y_pred_1, \"ood_dataset_2\": y_pred_2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = [\"RS-NN\", \"LB-BNN\", \"ENN\", \"CNN\"]\n",
    "ood_dataset_strings = [\"ood_dataset_1\", \"ood_dataset_2\"]\n",
    "\n",
    "for baseline in baselines:\n",
    "    for ood_dataset in ood_dataset_strings:\n",
    "        # Calculate AUROC and AUPRC\n",
    "        metrics_data = evaluate_metrics(baseline, ood_dataset, entropy(predictions_dict[baseline][selected_dataset]), entropy(predictions_dict[baseline][ood_dataset]))\n",
    "        \n",
    "for index, (dataset_name, baselines) in enumerate(metrics_data.items()):\n",
    "    name = ood_dataset_names[index]\n",
    "    print(f\"------------{dataset_name} ({name})------------\")\n",
    "    for model_name, metrics in baselines.items():\n",
    "        print(f\"{model_name} - AUROC: {metrics['AUROC']:.6f}\\tAUPRC: {metrics['AUPRC']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set(style=\"white\", palette=\"muted\")\n",
    "\n",
    "muted_colors = sns.color_palette(\"muted\", n_colors=len(models))\n",
    "\n",
    "# Create subplots with two rows for each dataset\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 3))\n",
    "legend_locs = ['lower right']*2+['lower left']*2\n",
    "\n",
    "for j, metric in enumerate([\"ROC Curve\", \"PRC Curve\"]):\n",
    "    for i, dataset in enumerate(ood_dataset_strings):\n",
    "        name = ood_dataset_names[i]\n",
    "\n",
    "        ax = axes[(j*2)+i]\n",
    "        ax.set_title(f'{name} - {metric}')\n",
    "        ax.set_xlabel('False Positive Rate (TPR)') if metric == \"ROC Curve\" else ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('True Positive Rate (FPR)') if metric == \"ROC Curve\" else ax.set_ylabel('Precision')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.0])\n",
    "        ax.grid(True)  # Remove the grid\n",
    "\n",
    "        # Apply milder tones to the line styles\n",
    "        ax.set_prop_cycle(cycler('color', muted_colors))\n",
    "\n",
    "        for k, baseline in enumerate(baselines):\n",
    "            fpr = metrics_data[dataset][baseline][\"fpr\"]\n",
    "            tpr = metrics_data[dataset][baseline][\"tpr\"]\n",
    "            precision = metrics_data[dataset][baseline][\"precision\"]\n",
    "            recall = metrics_data[dataset][baseline][\"recall\"]\n",
    "            auroc = metrics_data[dataset][baseline][\"AUROC\"]*100\n",
    "            auprc = metrics_data[dataset][baseline][\"AUPRC\"]*100\n",
    "\n",
    "            if metric == \"ROC Curve\":\n",
    "                ax.plot(fpr, tpr, label=f'{baseline}: {np.round(auroc,2)}')\n",
    "                auroc_index = np.argmax(tpr - fpr)\n",
    "                ax.scatter(fpr[auroc_index], tpr[auroc_index], marker='o', s=50)\n",
    "\n",
    "            else:\n",
    "                ax.plot(recall, precision, label=f'{baseline}: {np.round(auprc,2)}')\n",
    "                auprc_index = np.argmax(precision + recall)\n",
    "                ax.scatter(recall[auprc_index], precision[auprc_index], marker='o', s=50)\n",
    "\n",
    "        ax.legend(prop={'size': 10}, loc=legend_locs[(j*2)+i])\n",
    "        ax.margins(x=0)\n",
    "        for pos in ['right', 'top', 'bottom', 'left']: \n",
    "            ax.spines[pos].set_color(\"lightgray\") \n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_dataset_strings_with_iid = [selected_dataset] + ood_dataset_strings\n",
    "ood_dataset_names_with_iid = [selected_dataset] + ood_dataset_names\n",
    "confidence_dict = {baseline: {} for baseline in predictions_dict}\n",
    "\n",
    "for baseline in baselines:\n",
    "    for ood_dataset_str, ood_dataset_name in zip(ood_dataset_strings_with_iid, ood_dataset_names_with_iid):\n",
    "        confidence_values = np.max(predictions_dict[baseline][ood_dataset_str], axis = 1)\n",
    "        confidence_dict[baseline][ood_dataset_str] = confidence_values\n",
    "        mean_confidence = np.mean(confidence_values)\n",
    "        std_confidence = np.std(confidence_values)\n",
    "        \n",
    "        print(f\"Confidence of {baseline} on {ood_dataset_name} = {round(mean_confidence, 4)} +/- {round(std_confidence, 4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty Estimation - ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_dict = {baseline: {} for baseline in predictions_dict}\n",
    "\n",
    "for baseline in baselines:\n",
    "    for ood_dataset_str, ood_dataset_name in zip(ood_dataset_strings_with_iid, ood_dataset_names_with_iid):\n",
    "        entropy_values = entropy(predictions_dict[baseline][ood_dataset_str])\n",
    "        entropy_dict[baseline][ood_dataset_str] = entropy_values\n",
    "        mean_entropy = np.mean(entropy_values)\n",
    "        std_entropy = np.std(entropy_values)\n",
    "        \n",
    "        print(f\"Entropy of {baseline} on {ood_dataset_name} = {round(mean_entropy, 4)} +/- {round(std_entropy, 4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, sharex=True, facecolor='w', )\n",
    "\n",
    "bins = 30\n",
    "\n",
    "ax.hist(entropy(predictions_dict[\"RS-NN\"][selected_dataset]), bins, weights=np.ones(len(predictions_dict[\"RS-NN\"][selected_dataset])) / len(predictions_dict[\"RS-NN\"][selected_dataset]), alpha=0.7, label=f'{selected_dataset}')\n",
    "ax.hist(entropy(predictions_dict[\"RS-NN\"][\"ood_dataset_1\"]), bins, weights=np.ones(len(predictions_dict[\"RS-NN\"][\"ood_dataset_1\"])) / len(predictions_dict[\"RS-NN\"][\"ood_dataset_1\"]), alpha=0.7, label=f'{ood_dataset_1}')\n",
    "ax.hist(entropy(predictions_dict[\"RS-NN\"][\"ood_dataset_2\"]), bins, weights=np.ones(len(predictions_dict[\"RS-NN\"][\"ood_dataset_2\"])) / len(predictions_dict[\"RS-NN\"][\"ood_dataset_2\"]), alpha=0.7, label=f'{ood_dataset_2}')\n",
    "\n",
    "ax.legend(prop={\"size\": 12})\n",
    "ax.set_ylabel(\"Density\", fontsize=12)\n",
    "ax.set_xlabel(\"Entropy\", fontsize=12)\n",
    "plt.title(\"Entropy Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "fontsize = 15\n",
    "\n",
    "base = np.e\n",
    "hist_iid = np.emath.logn(base, np.histogram2d(entropy_dict[\"RS-NN\"][selected_dataset], confidence_dict[\"RS-NN\"][selected_dataset], bins=30)[0].T + 1e-31)\n",
    "hist_svhn = np.emath.logn(base, np.histogram2d(entropy_dict[\"RS-NN\"][\"ood_dataset_1\"], confidence_dict[\"RS-NN\"][\"ood_dataset_1\"], bins=30)[0].T + 1e-31)\n",
    "hist_intel = np.emath.logn(base, np.histogram2d(entropy_dict[\"RS-NN\"][\"ood_dataset_2\"], confidence_dict[\"RS-NN\"][\"ood_dataset_2\"], bins=30)[0].T + 1e-31)\n",
    "\n",
    "col_name = \"viridis\"\n",
    "color_palette = sns.color_palette(col_name, as_cmap=True)\n",
    "\n",
    "sns.heatmap(data=hist_iid, cmap=color_palette, cbar=False, ax=axes[0], cbar_kws={'label': 'Frequency'}, vmin=0, vmax=np.max(hist_iid))\n",
    "sns.heatmap(data=hist_svhn, cmap=color_palette, cbar=False, ax=axes[1], cbar_kws={'label': 'Frequency'}, vmin=0, vmax=np.max(hist_iid))\n",
    "sns.heatmap(data=hist_intel, cmap=color_palette, cbar=True, ax=axes[2], cbar_kws={'label': 'Frequency'}, vmin=0, vmax=np.max(hist_iid))\n",
    "\n",
    "axes[0].set_title(\"iD: CIFAR10\", fontsize=fontsize)\n",
    "axes[1].set_title(\"OoD: SVHN\", fontsize=fontsize)\n",
    "axes[2].set_title(\"OoD: Intel Image\", fontsize=fontsize)\n",
    "\n",
    "for ax in axes:\n",
    "    try:\n",
    "        ax.collections[0].colorbar.set_label('Log Frequency', fontsize=fontsize)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_xticks(np.linspace(0, 30, 5))\n",
    "    ax.set_xticklabels(np.round(np.linspace(0, 3.5, 5), 2), rotation=0)\n",
    "\n",
    "axes[0].set_yticks(np.linspace(0, 30, 5))\n",
    "axes[0].set_yticklabels(np.round(np.linspace(0, 1, 5), 2))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_xlabel(\"Entropy\", fontsize=fontsize)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "axes[0].set_ylabel(\"Confidence Score\", fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Normalized Heatmaps of Confidence vs. Entropy for different datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty Estimation - CREDAL SET WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mass functions to compute credal set vertices  \n",
    "test_preds_mass_1 = test_preds_masses[ood_dataset_1]\n",
    "test_preds_mass_2 = test_preds_masses[ood_dataset_2]\n",
    "\n",
    "rsnn_dict = {\n",
    "    selected_dataset: {\"final_bet_p\": final_bet_p, \"test_preds_mass\": test_preds_mass},\n",
    "    \"ood_dataset_1\": {\"final_bet_p\": final_bet_p_1, \"test_preds_mass\": test_preds_mass_1},\n",
    "    \"ood_dataset_2\": {\"final_bet_p\": final_bet_p_2, \"test_preds_mass\": test_preds_mass_2}\n",
    "}\n",
    "\n",
    "vertices_list_dict = {}\n",
    "\n",
    "# Loop through each dataset\n",
    "for dataset_name, values in rsnn_dict.items():\n",
    "    final_bet_p_dataset = values[\"final_bet_p\"]\n",
    "    test_preds_mass_dataset = values[\"test_preds_mass\"]\n",
    "    vertices_list = []\n",
    "    for k in range(len(final_bet_p_dataset)):\n",
    "        vertices_list.append(compute_vertices(test_preds_mass_dataset[k], classes, np.argmax(final_bet_p, axis = -1)[k], new_classes_with_full))\n",
    "    \n",
    "    # Save vertices_list for the current dataset\n",
    "    vertices_list_dict[dataset_name] = np.array(vertices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credal_set_width_dict = {dataset_name: {} for dataset_name in vertices_list_dict}\n",
    "\n",
    "# Loop through each dataset\n",
    "for dataset_name, vertices_list in vertices_list_dict.items():\n",
    "    credal_set_width_values = np.max(vertices_list, axis=1) - np.min(vertices_list, axis=1)\n",
    "    credal_set_width_dict[dataset_name] = credal_set_width_values\n",
    "    mean_width = np.mean(credal_set_width_values)\n",
    "    std_width = np.std(credal_set_width_values)\n",
    "    \n",
    "    print(f\"Credal set width for {dataset_name} : {mean_width} +/- {std_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_lists = [vertices_list_dict[dataset] for dataset in ood_dataset_strings_with_iid]\n",
    "\n",
    "# Loop through each dataset\n",
    "for idx, (dataset_name, vertices_list) in enumerate(zip(ood_dataset_strings_with_iid, vertices_lists)):\n",
    "    # Create subplots for each dataset\n",
    "    fig, ax = plt.subplots(figsize=(15, 1)) \n",
    "    font = {'family': 'sans-serif', 'weight': 'normal', 'size': 8}\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    # Plot the max and min P values\n",
    "    ax.plot(np.max(vertices_list[:100], axis=-1), color='red', label='Max P', linewidth=0.7, linestyle=\"dotted\", alpha=0.7)\n",
    "    ax.plot(np.min(vertices_list[:100], axis=-1), color='red', label='Min P', linewidth=0.7, linestyle=\"dotted\", alpha=0.7)\n",
    "\n",
    "    # Fill the area between max and min P\n",
    "    ax.fill_between(np.arange(100), np.max(vertices_list[:100], axis=-1), np.min(vertices_list[:100], axis=-1), color='red', alpha=.09)\n",
    "    \n",
    "    plt.xlabel('Samples', fontdict=font)\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.title(f\"Credal Set Plot - {ood_dataset_names_with_iid[idx]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viridisBig2 = cm.get_cmap('Oranges_r', 512)\n",
    "newcmp2 = ListedColormap(viridisBig2(np.linspace(0, 0.25, 256)))\n",
    "viridisBig = cm.get_cmap('viridis', 512)\n",
    "newcmp = ListedColormap(viridisBig(np.linspace(0.20, 0.45, 256)))\n",
    "\n",
    "num_samples_to_disp = 5000\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "\n",
    "for idx, (dataset_key, vertices_list) in enumerate(zip(ood_dataset_strings_with_iid, vertices_lists)):\n",
    "    # Extract data for the current dataset\n",
    "    dataset_data = rsnn_dict[dataset_key]\n",
    "    final_bet_p_dataset = dataset_data[\"final_bet_p\"]\n",
    "\n",
    "    # Skip datasets other than CIFAR-10\n",
    "    if dataset_key != selected_dataset:\n",
    "        continue\n",
    "\n",
    "    # Create correct and incorrect indices for the current dataset\n",
    "    correct_idx, incorrect_idx = compute_correct_incorrect_indices(final_bet_p_dataset, y_test)\n",
    "\n",
    "    subset_incorrect_indices = incorrect_idx[incorrect_idx < num_samples_to_disp]\n",
    "    subset_incorrect = vertices_list[subset_incorrect_indices]\n",
    "\n",
    "    max_values_incorrect = np.max(subset_incorrect, axis=1)\n",
    "    min_values_incorrect = np.min(subset_incorrect, axis=1)\n",
    "\n",
    "    x_incorrect = np.arange(len(vertices_list))[subset_incorrect_indices]\n",
    "\n",
    "    for i in range(len(subset_incorrect)):\n",
    "        cmap_incorrect = plt.cm.get_cmap(newcmp2)\n",
    "        color_incorrect = cmap_incorrect((max_values_incorrect[i] + min_values_incorrect[i]) / 2)\n",
    "        ax.vlines(x_incorrect[i], ymin=min_values_incorrect[i], ymax=max_values_incorrect[i], color=color_incorrect, alpha=0.7)\n",
    "\n",
    "    cmap_incorrect = plt.cm.get_cmap(newcmp2)\n",
    "    max_colors_incorrect = cmap_incorrect(max_values_incorrect)\n",
    "    min_colors_incorrect = cmap_incorrect(min_values_incorrect)\n",
    "    ax.scatter(x_incorrect, max_values_incorrect, marker='_', s=10, c=max_colors_incorrect, label='Incorrectly Classified')\n",
    "    ax.scatter(x_incorrect, min_values_incorrect, marker='_', s=10, c=min_colors_incorrect)\n",
    "    \n",
    "    subset_correct_indices = correct_idx[correct_idx < num_samples_to_disp]\n",
    "    subset_correct = vertices_list[subset_correct_indices]\n",
    "\n",
    "    max_values_correct = np.max(subset_correct, axis=1)\n",
    "    min_values_correct = np.min(subset_correct, axis=1)\n",
    "\n",
    "    x_correct = np.arange(len(vertices_list))[subset_correct_indices]\n",
    "\n",
    "    for i in range(len(subset_correct)):\n",
    "        cmap_correct = plt.cm.get_cmap(newcmp)\n",
    "        color_correct = cmap_correct((max_values_correct[i] + min_values_correct[i]) / 2)\n",
    "        ax.vlines(x_correct[i], ymin=min_values_correct[i], ymax=max_values_correct[i], color=color_correct, alpha=0.7)\n",
    "\n",
    "    cmap_correct = plt.cm.get_cmap(newcmp)\n",
    "    max_colors_correct = cmap_correct(max_values_correct)\n",
    "    min_colors_correct = cmap_correct(min_values_correct)\n",
    "    ax.scatter(x_correct, max_values_correct, marker='_', s=10, c=max_colors_correct, label='Correctly Classified')\n",
    "    ax.scatter(x_correct, min_values_correct, marker='_', s=10, c=min_colors_correct)\n",
    "\n",
    "    ax.set_xlabel('Samples', fontsize=12)\n",
    "    ax.set_ylabel('Extremal probability', fontsize=12)\n",
    "    ax.set_title(f'Credal Set Width - {ood_dataset_names_with_iid[idx]}', fontsize=14)\n",
    "\n",
    "    ax.legend(prop={\"size\": 12}, markerscale=5.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "fontsize = 15\n",
    "\n",
    "base = np.e\n",
    "hist_iid = np.emath.logn(base, np.histogram2d(credal_set_width_dict[selected_dataset], confidence_dict[\"RS-NN\"][selected_dataset], bins=30)[0].T + 1e-31)\n",
    "hist_svhn = np.emath.logn(base, np.histogram2d(credal_set_width_dict[\"ood_dataset_1\"], confidence_dict[\"RS-NN\"][\"ood_dataset_1\"], bins=30)[0].T + 1e-31)\n",
    "hist_intel = np.emath.logn(base, np.histogram2d(credal_set_width_dict[\"ood_dataset_2\"], confidence_dict[\"RS-NN\"][\"ood_dataset_2\"], bins=30)[0].T + 1e-31)\n",
    "\n",
    "col_name = \"viridis\"\n",
    "color_palette = sns.color_palette(col_name, as_cmap=True)\n",
    "\n",
    "sns.heatmap(data=hist_iid, cmap=color_palette, cbar=False, ax=axes[0], cbar_kws={'label': 'Frequency'}, vmin=0, vmax=np.max(hist_iid))\n",
    "sns.heatmap(data=hist_svhn, cmap=color_palette, cbar=False, ax=axes[1], cbar_kws={'label': 'Frequency'}, vmin=0, vmax=np.max(hist_iid))\n",
    "sns.heatmap(data=hist_intel, cmap=color_palette, cbar=True, ax=axes[2], cbar_kws={'label': 'Frequency'}, vmin=0, vmax=np.max(hist_iid))\n",
    "\n",
    "axes[0].set_title(\"iD: CIFAR10\", fontsize=fontsize)\n",
    "axes[1].set_title(\"OoD: SVHN\", fontsize=fontsize)\n",
    "axes[2].set_title(\"OoD: Intel Image\", fontsize=fontsize)\n",
    "\n",
    "for ax in axes:\n",
    "    try:\n",
    "        ax.collections[0].colorbar.set_label('Log Frequency', fontsize=fontsize)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_xticks(np.linspace(0, 30, 5))\n",
    "    ax.set_xticklabels(np.round(np.linspace(0, 3.5, 5), 2), rotation=0)\n",
    "\n",
    "axes[0].set_yticks(np.linspace(0, 30, 5))\n",
    "axes[0].set_yticklabels(np.round(np.linspace(0, 1, 5), 2))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_xlabel(\"Credal Set Width\", fontsize=fontsize)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "axes[0].set_ylabel(\"Confidence Score\", fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Normalized Heatmaps of Confidence vs. Credal Set Width for different datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial samples - NOISY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change scales to test the model's robustness\n",
    "x_test_noisy = add_random_noise(x_test, scale = 0.4)\n",
    "x_test_org_noisy = add_random_noise(x_test_org, scale = 0.4)\n",
    "\n",
    "# Get predictions and calculate accuracy of RS-NN\n",
    "test_preds_noisy = new_model.predict(x_test_noisy, verbose=1)\n",
    "test_preds_mass_noisy = belief_to_mass(test_preds_noisy, list(new_classes))\n",
    "final_bet_p_noisy = final_betp(test_preds_mass_noisy, classes, new_classes_with_full)\n",
    "final_bet_p_indices_noisy = np.argmax(final_bet_p_noisy, axis = -1)\n",
    "accuracy_noisy = (np.sum(final_bet_p_indices_noisy == y_test)/len(y_test))*100\n",
    "print(f\"Test Accuracy of RS-NN on Noisy test images using pignistic probability: {accuracy_noisy}%\")\n",
    "\n",
    "# Get predictions and calculate accuracy of CNN\n",
    "y_pred_noisy = model.predict(x_test_noisy)\n",
    "score_noisy = model.evaluate(x_test_noisy, y_test_one_hot)\n",
    "print(f\"Test Accuracy of standard CNN on Noisy test images: {score_noisy[1]*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial samples - ROTATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change rotation angles to test the model's robustness\n",
    "x_test_rotated = rotate_images(x_test, start_angle = -30, end_angle= 90)\n",
    "x_test_org_rotated = rotate_images(x_test_org, start_angle = -30, end_angle= 90)\n",
    "\n",
    "# Get predictions and calculate accuracy of RS-NN\n",
    "test_preds_rotated = new_model.predict(x_test_rotated, verbose=1)\n",
    "test_preds_mass_rotated = belief_to_mass(test_preds_rotated, list(new_classes))\n",
    "final_bet_p_rotated = final_betp(test_preds_mass_rotated, classes, new_classes_with_full)\n",
    "final_bet_p_indices_rotated = np.argmax(final_bet_p_rotated, axis = -1)\n",
    "accuracy_rotated = (np.sum(final_bet_p_indices_rotated == y_test)/len(y_test))*100\n",
    "print(f\"Test Accuracy of RS-NN on Rotated test images using pignistic probability: {accuracy_rotated}%\")\n",
    "\n",
    "# Get predictions and calculate accuracy of CNN\n",
    "y_pred_rotated = model.predict(x_test_rotated)\n",
    "score_rotated = model.evaluate(x_test_rotated, y_test_one_hot)\n",
    "print(f\"Test Accuracy of standard CNN on Rotated test images : {score_rotated[1]*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Calibration Error(ECE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_value = expected_calibration_error(final_bet_p, np.argmax(final_bet_p, axis=-1), y_test, 5)\n",
    "print(f\"Expected Calibration Error (ECE) of RS-NN on CIFAR10: {ece_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_print_metrics(predictions_dict, selected_dataset, y_true):\n",
    "    for model_name, model_predictions in predictions_dict.items():\n",
    "        if selected_dataset in model_predictions:\n",
    "            calculate_and_print_ece(model_predictions[selected_dataset], y_true, f\"{model_name} - {selected_dataset}\")\n",
    "\n",
    "evaluate_and_print_metrics(predictions_dict, selected_dataset, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
