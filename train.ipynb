{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 20:09:15.997468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-18 20:09:15.997533: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-18 20:09:15.997910: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 20:09:16.038589: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 20:09:18.719001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79078 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:24:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# # To use single-GPU\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_visible_devices(physical_devices[1], 'GPU') # Specify GPU id\n",
    "# logical_devices = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "# To use multiple GPUs, uncomment the following:\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    num_gpus = len(gpus)\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    # Set GPUs to use. For example, limit TensorFlow to use 3 GPUs\n",
    "    tf.config.experimental.set_visible_devices(gpus[2], 'GPU')\n",
    "    \n",
    "# Create a MirroredStrategy for multi-GPU use\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import  Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from data.id_dataloader import load_cifar10, load_intel_image, load_mnist, load_cifar100\n",
    "from data.classes import cifar10_classes, mnist_classes, intel_image_classes, cifar100_classes\n",
    "\n",
    "from models.models import resnet50, wideresnet2810, vgg16, inceptionv3, efficientnetb2\n",
    "from models.pretrained_models import pretrained_resnet50, pretrained_vgg16\n",
    "\n",
    "from rsnn_functions.budgeting import train_embeddings, fit_gmm, ellipse, overlaps\n",
    "from rsnn_functions.bf_encoding_gt import groundtruthmod\n",
    "from rsnn_functions.belief_mass_betp import belief_to_mass, mass_coeff, final_betp\n",
    "from rsnn_functions.rsnn_loss import BinaryCrossEntropy\n",
    "\n",
    "from utils.train_utils import lr_schedule, train_val_split, data_generator, lr_callbacks, save_model_and_weights\n",
    "from utils.eval_utils import load_model, load_all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters \n",
    "k = 20  #number of number of non-singleton focal sets \n",
    "batch_size = 128\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = {\"cifar10\": 10, \"mnist\": 10, \"intel_image\": 6, \"cifar100\": 100, \"svhn\": 10, \"fmnist\": 10, \"kmnist\":10}\n",
    "\n",
    "dataset_loader = {\n",
    " \"cifar10\": load_cifar10, \n",
    " \"mnist\": load_mnist, \n",
    " \"intel_image\": load_intel_image, \n",
    " \"cifar100\": load_cifar100, \n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"resnet50\": resnet50, \n",
    "    \"wideresnet_28_10\": wideresnet2810, \n",
    "    \"vgg16\": vgg16,\n",
    "    \"inception_v3\": inceptionv3,\n",
    "    \"efficientnet_b2\": efficientnetb2\n",
    "}\n",
    "\n",
    "pretrained_models = {\n",
    "    \"pretrained_resnet50\": pretrained_resnet50, \n",
    "    \"pretrained_vgg16\": pretrained_vgg16,\n",
    "}\n",
    "\n",
    "class_list_functions = {\n",
    "    \"cifar10\": cifar10_classes,\n",
    "     \"mnist\": mnist_classes, \n",
    "    \"intel_image\": intel_image_classes, \n",
    "    \"cifar100\": cifar100_classes, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Shape of x_train: (40000, 32, 32, 3)\n",
      "Shape of x_test: (10000, 32, 32, 3)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Define configurations\n",
    "selected_dataset = \"cifar10\"  # Choose the dataset\n",
    "selected_model = \"resnet50\"   # Choose the model\n",
    "\n",
    "# Class list\n",
    "classes = class_list_functions[selected_dataset]()\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "num_clusters = len(classes)\n",
    "classes_dict = {c:num for c,num in zip(classes, range(len(classes)))}\n",
    "classes_dict_inverse = {num:c for c,num in zip(classes, range(len(classes)))}\n",
    "\n",
    "# Load dataset based on selected_dataset\n",
    "x_train, y_train, x_test_org, x_test, y_test = dataset_loader[selected_dataset]()\n",
    "\n",
    "# Infer input_shape based on selected_dataset\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Train-validation split\n",
    "x_train, y_train, y_train_one_hot, x_val, y_val, y_val_one_hot = train_val_split(x_train, y_train, num_classes[selected_dataset], val_samples=-10000)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of x_val:\", x_val.shape)\n",
    "\n",
    "# Learning rate scheduler\n",
    "callbacks = lr_callbacks(lr_schedule)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = data_generator(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Load saved CNN model\n",
    "\"\"\"\n",
    "# For single-GPU run, comment with strategy.scope():\n",
    "# Multi-GPU run\n",
    "with strategy.scope():      \n",
    "    # Create the model based on selected_model\n",
    "    if selected_model in pretrained_models:\n",
    "        model = pretrained_models[selected_model](input_shape=input_shape, num_classes=num_classes[selected_dataset], final_activation='softmax')\n",
    "    else:\n",
    "        model = models[selected_model](input_shape=input_shape, num_classes=num_classes[selected_dataset], final_activation='softmax')\n",
    "\n",
    "    # Compile the model \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=\"adam\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model = load_model(selected_model, selected_dataset, model_type = \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model and weights\n",
    "# save_model_and_weights(model, selected_model, selected_dataset, model_type='CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUDGETING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from the penultimate layer\n",
    "aux_model = Model(model.input, model.layers[-2].output)\n",
    "\n",
    "# 3D feature space respresentation of class embeddings\n",
    "train_embedded_tsne = train_embeddings(aux_model, x_train, batch_size)\n",
    "\n",
    "# Creating figure\n",
    "plt.figure(figsize=(16, 9), dpi=80)\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "for i in range(len(classes)):\n",
    "  ax.scatter3D(train_embedded_tsne[y_train == i][:,0], train_embedded_tsne[y_train == i][:,1], train_embedded_tsne[y_train == i][:,2], label=classes[i])\n",
    "plt.legend()\n",
    " \n",
    "# show plot\n",
    "plt.show()\n",
    "\n",
    "# Fitting Gaussian Mixture Models (GMM) to individual classes\n",
    "individual_gms = fit_gmm(classes, train_embedded_tsne, y_train)\n",
    "\n",
    "# Calculating clusters for each class\n",
    "regions, means, max_len = ellipse(individual_gms, num_classes[selected_dataset])\n",
    "\n",
    "# Compute the overlap and choose the sets of classes with highest overlap\n",
    "new_classes = overlaps(k, classes, num_clusters, classes_dict, regions, means, max_len)\n",
    "\n",
    "# np.save('new_classes.npy', new_classes)\n",
    "print(new_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved new_classes\n",
    "# new_classes = np.load('new_classes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Belief-encoding of the ground truth\n",
    "y_train_modified = groundtruthmod(y_train, classes, new_classes, classes_dict_inverse)\n",
    "y_val_modified = groundtruthmod(y_val, classes, new_classes, classes_dict_inverse)\n",
    "y_test_modified = groundtruthmod(y_test, classes, new_classes, classes_dict_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RS-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For single-GPU run, comment with strategy.scope():\n",
    "# Multi-GPU run\n",
    "with strategy.scope():      \n",
    "    # Create the model based on selected_model\n",
    "    if selected_model in pretrained_models:\n",
    "        new_model = pretrained_models[selected_model](input_shape=input_shape,  num_classes=len(new_classes), final_activation='sigmoid')\n",
    "    else:\n",
    "        new_model = models[selected_model](input_shape=input_shape, num_classes=len(new_classes), final_activation='sigmoid')\n",
    "\n",
    "    # Compile the model \n",
    "    new_model.compile(loss=BinaryCrossEntropy,\n",
    "                optimizer=\"adam\",\n",
    "                metrics=['binary_accuracy'])\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_new = new_model.fit(datagen.flow(x_train, y_train_modified, batch_size=batch_size),\n",
    "                    validation_data=(x_val, y_val_modified),\n",
    "                    epochs=epochs, verbose=1, workers=2,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_new = new_model.fit(datagen.flow(x_train, y_train_modified, batch_size=batch_size),\n",
    "                    validation_data=(x_val, y_val_modified),\n",
    "                    epochs=epochs, verbose=1, workers=2,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model and weights\n",
    "# save_model_and_weights(new_model, selected_model, selected_dataset, model_type='RSNN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
