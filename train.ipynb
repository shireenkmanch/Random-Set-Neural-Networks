{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import  Model\n",
    "import numpy as np\n",
    "\n",
    "from data.id_dataloader import load_cifar10, load_intel_image, load_mnist, load_cifar100\n",
    "from data.classes import cifar10_classes, mnist_classes, intel_image_classes, cifar100_classes\n",
    "\n",
    "from models.models import resnet50, wideresnet2810, vgg16, inceptionv3, efficientnetb2\n",
    "from models.pretrained_models import pretrained_resnet50, pretrained_vgg16\n",
    "\n",
    "from rsnn_functions.budgeting import train_embeddings, fit_gmm, ellipse, overlaps\n",
    "from rsnn_functions.bf_encoding_gt import groundtruthmod\n",
    "from rsnn_functions.belief_mass_betp import belief_to_mass, mass_coeff, final_betp\n",
    "from rsnn_functions.rsnn_loss import BinaryCrossEntropy\n",
    "\n",
    "from utils.train_utils import lr_schedule, train_val_split, data_generator, lr_callbacks, save_model_and_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    num_gpus = len(gpus)\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    # Set GPUs to use. For example, limit TensorFlow to use 3 GPUs\n",
    "    tf.config.experimental.set_visible_devices(gpus[:3], 'GPU')\n",
    "    \n",
    "# Create a MirroredStrategy for multi-GPU use\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters \n",
    "k = 20  #number of number of non-singleton focal sets \n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = {\"cifar10\": 10, \"mnist\": 10, \"intel_image\": 6, \"cifar100\": 100, \"svhn\": 10, \"fmnist\": 10, \"kmnist\":10}\n",
    "\n",
    "dataset_loader = {\n",
    " \"cifar10\": load_cifar10, \n",
    " \"mnist\": load_mnist, \n",
    " \"intel_image\": load_intel_image, \n",
    " \"cifar100\": load_cifar100, \n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"resnet50\": resnet50, \n",
    "    \"wideresnet_28_10\": wideresnet2810, \n",
    "    \"vgg16\": vgg16,\n",
    "    \"inception_v3\": inceptionv3,\n",
    "    \"efficientnet_b2\": efficientnetb2\n",
    "}\n",
    "\n",
    "pretrained_models = {\n",
    "    \"pretrained_resnet50\": pretrained_resnet50, \n",
    "    \"pretrained_vgg16\": pretrained_vgg16,\n",
    "}\n",
    "\n",
    "class_list_functions = {\n",
    "    \"cifar10\": cifar10_classes,\n",
    "     \"mnist\": mnist_classes, \n",
    "    \"intel_image\": intel_image_classes, \n",
    "    \"cifar100\": cifar100_classes, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configurations\n",
    "selected_dataset = \"cifar10\"  # Choose the dataset\n",
    "selected_model = \"resnet50\"   # Choose the model\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "# Class list\n",
    "classes = class_list_functions[selected_dataset]()\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "num_clusters = len(classes)\n",
    "classes_dict = {c:num for c,num in zip(classes, range(len(classes)))}\n",
    "classes_dict_inverse = {num:c for c,num in zip(classes, range(len(classes)))}\n",
    "\n",
    "# Load dataset based on selected_dataset\n",
    "x_train, y_train, x_test_org, x_test, y_test = dataset_loader[selected_dataset]()\n",
    "\n",
    "# Infer input_shape based on selected_dataset\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Train-validation split\n",
    "x_train, y_train, y_train_one_hot, x_val, y_val, y_val_one_hot = train_val_split(x_train, y_train, num_classes[selected_dataset], val_samples=-10000)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of x_val:\", x_val.shape)\n",
    "\n",
    "# Learning rate scheduler\n",
    "callbacks = lr_callbacks(lr_schedule)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = data_generator(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-GPU run\n",
    "with strategy.scope():      \n",
    "    # Create the model based on selected_model\n",
    "    if selected_model in pretrained_models:\n",
    "        model = pretrained_models[selected_model](input_shape=input_shape,  num_classes=num_classes[selected_dataset], final_activation='softmax')\n",
    "    else:\n",
    "        model = models[selected_model](input_shape=input_shape, num_classes=num_classes[selected_dataset], final_activation='softmax')\n",
    "\n",
    "    # Compile the model \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=\"adam\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(x_train, y_train_one_hot, batch_size=batch_size),\n",
    "                    validation_data=(x_val, y_val_one_hot),\n",
    "                    epochs=epochs, verbose=1, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model and weights\n",
    "# save_model_and_weights(model, selected_model, selected_dataset, model_type='CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUDGETING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from the penultimate layer\n",
    "aux_model = Model(model.input, model.layers[-2].output)\n",
    "\n",
    "# 3D feature space respresentation of class embeddings\n",
    "train_embedded_tsne = train_embeddings(aux_model, x_train, batch_size)\n",
    "\n",
    "# Fitting Gaussian Mixture Models (GMM) to individual classes\n",
    "individual_gms = fit_gmm(classes, train_embedded_tsne, y_train)\n",
    "\n",
    "# Calculating clusters for each class\n",
    "regions, means, max_len = ellipse(individual_gms, num_classes[selected_dataset])\n",
    "\n",
    "# Compute the overlap and choose the sets of classes with highest overlap\n",
    "new_classes = overlaps(k, classes, num_clusters, classes_dict, regions, means, max_len)\n",
    "\n",
    "# np.save('new_classes.npy', new_classes)\n",
    "print(new_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved new_classes\n",
    "# new_classes = np.load('new_classes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Belief-encoding of the ground truth\n",
    "y_train_modified = groundtruthmod(y_train, classes, new_classes, classes_dict_inverse)\n",
    "y_val_modified = groundtruthmod(y_val, classes, new_classes, classes_dict_inverse)\n",
    "y_test_modified = groundtruthmod(y_test, classes, new_classes, classes_dict_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RS-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-GPU run\n",
    "with strategy.scope():      \n",
    "    # Create the model based on selected_model\n",
    "    if selected_model in pretrained_models:\n",
    "        new_model = pretrained_models[selected_model](input_shape=input_shape,  num_classes=len(new_classes), final_activation='sigmoid')\n",
    "    else:\n",
    "        new_model = models[selected_model](input_shape=input_shape, num_classes=len(new_classes), final_activation='sigmoid')\n",
    "\n",
    "    # Compile the model \n",
    "    new_model.compile(loss=BinaryCrossEntropy,\n",
    "                optimizer=\"adam\",\n",
    "                metrics=['binary_accuracy'])\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_new = new_model.fit(datagen.flow(x_train, y_train_modified, batch_size=batch_size),\n",
    "                    validation_data=(x_val, y_val_modified),\n",
    "                    epochs=epochs, verbose=1, workers=2,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_new = new_model.fit(datagen.flow(x_train, y_train_modified, batch_size=batch_size),\n",
    "                    validation_data=(x_val, y_val_modified),\n",
    "                    epochs=epochs, verbose=1, workers=2,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model and weights\n",
    "# save_model_and_weights(new_model, selected_model, selected_dataset, model_type='RSNN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
